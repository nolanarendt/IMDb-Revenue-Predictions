{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Extra Trees Regression\n",
    "![ImdbIcon](../images/imdbheader.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nolan_fur2pfn\\.conda\\envs\\dsi\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\nolan_fur2pfn\\.conda\\envs\\dsi\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\nolan_fur2pfn\\.conda\\envs\\dsi\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalscore_df = pd.read_csv('../data/totalscore_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_title', 'year', 'actors', 'plot', 'duration', 'Action',\n",
       "       'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary',\n",
       "       'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music',\n",
       "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
       "       'Sport', 'Thriller', 'War', 'Western', 'avg_vote', 'votes',\n",
       "       'weighted_average_vote', 'total_votes', 'mean_vote', 'median_vote',\n",
       "       'votes_1', 'votes_2', 'votes_3', 'votes_4', 'votes_5', 'votes_6',\n",
       "       'votes_7', 'votes_8', 'votes_9', 'votes_10', 'us_voters_rating',\n",
       "       'us_voters_votes', 'plot_sentiment', 'director_score', 'actor_score',\n",
       "       'actress_score', 'total_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalscore_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Drama', 'Family', 'Fantasy', 'History', \n",
    "            'Horror', 'Music', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Sport', 'Thriller',\n",
    "            'votes_4', 'votes_5', 'votes_6', 'votes_7', 'votes_8','votes_9', 'votes_10', \n",
    "            'director_score', 'actor_score', 'actress_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = totalscore_df[features]\n",
    "y = totalscore_df['total_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesRegressor()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.8701953463170574\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Score:\", et.score(X_train, y_train))\n",
    "print(\"Testing Score:\", et.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val Score: 0.868577457905728\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross Val Score:\", cross_val_score(et, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {}\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>best_score</th>\n",
       "      <th>training_score</th>\n",
       "      <th>testing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.848339</td>\n",
       "      <td>0.949338</td>\n",
       "      <td>0.843390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>0.870884</td>\n",
       "      <td>0.999790</td>\n",
       "      <td>0.871853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.871947</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>0.871736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>0.871673</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>0.873723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>0.871905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_7</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>0.871927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.871710</td>\n",
       "      <td>0.999345</td>\n",
       "      <td>0.871223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_9</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>350</td>\n",
       "      <td>0.871838</td>\n",
       "      <td>0.999338</td>\n",
       "      <td>0.872032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         max_depth  min_samples_leaf  min_samples_split  n_estimators  \\\n",
       "model_1         15                 2                  2           100   \n",
       "model_2         25                 1                  2           300   \n",
       "model_3         35                 1                  2           200   \n",
       "model_4         35                 1                  2           300   \n",
       "model_5         30                 1                  2           300   \n",
       "model_6         35                 1                  2           300   \n",
       "model_7         35                 1                  2           400   \n",
       "model_8         35                 1                  3           400   \n",
       "model_9         40                 1                  3           350   \n",
       "\n",
       "         best_score  training_score  testing_score  \n",
       "model_1    0.848339        0.949338       0.843390  \n",
       "model_2    0.870884        0.999790       0.871853  \n",
       "model_3    0.871947        1.000000       0.872013  \n",
       "model_4    0.871736        1.000000       0.872862  \n",
       "model_5    0.871673        0.999997       0.873723  \n",
       "model_6    0.871905        1.000000       0.870866  \n",
       "model_7    0.871927        1.000000       0.871804  \n",
       "model_8    0.871710        0.999345       0.871223  \n",
       "model_9    0.871838        0.999338       0.872032  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_params = {\n",
    "    'max_depth': [30, 35, 40],\n",
    "    'min_samples_leaf': [0, 1, 2],\n",
    "    'min_samples_split': [3, 4, 5],\n",
    "    'n_estimators': [350, 400, 450],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(et, param_grid=et_params, cv = 5, n_jobs = 12)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "count += 1\n",
    "\n",
    "gs.best_params_['best_score'] = gs.best_score_\n",
    "\n",
    "gs.best_params_['training_score'] = gs.score(X_train, y_train)\n",
    "\n",
    "gs.best_params_['testing_score'] = gs.score(X_test, y_test)\n",
    "\n",
    "model_params[f'model_{count}'] = gs.best_params_\n",
    "\n",
    "model_df = pd.DataFrame.from_dict(model_params, orient='index')\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
